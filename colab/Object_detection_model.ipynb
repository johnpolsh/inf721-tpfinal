{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78CEeCESIMWb"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/johnpolsh/inf721-tpfinal/blob/main/colab/Object_detection_model.ipynb)\n",
        "# Setup\n",
        "### Download dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install wget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Default imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfznvUtUlvVN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import wget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fouOM7wxIMWg"
      },
      "source": [
        "### Select back-end device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaxflJNFIMWg"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch.set_default_device(device)\n",
        "\n",
        "print(f\"Using {device} as default device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Downloading datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metadata = \"https://scontent.fplu8-1.fna.fbcdn.net/m1/v/t6/An8K4G08lXqX2Om6ZxT8yc0w9oEoqNjimpfZSGFLENsvJ3xB4nuKak0A762P82rRnwptKSXdgwHQm1cdHgKqRu2tTsutxrPfiz_kApnl3AmOSQNiU2njLSlnjxlI.json?ccb=10-5&oh=00_AfD3JBYfL1cuglzrrKOiqEeDBIXH7dMtDk_Ha8HzuulqZg&oe=658FF6FB&_nc_sid=a7aa5b\"\n",
        "train = \"https://scontent.fplu8-1.fna.fbcdn.net/m1/v/t6/An-WS2mQvnrkM05xVRmd4NwzvUG42KxJV294Caeos-c0h8-XkxRyU9m4AdDvW5x9Sgxi4xHcXHkVkk0JyKtRZCmwCyw04Z-0ulrwQNAayOqnMvDkJvhL3nKJgtcUrA.json?ccb=10-5&oh=00_AfBbM0WoaaXAVNwoiJ1ahvpcNMs5tw-mpiTUAKXAmCfTqQ&oe=658DB23C&_nc_sid=a7aa5b\"\n",
        "eval = \"https://scontent.fplu8-1.fna.fbcdn.net/m1/v/t6/An8ggk-BJQsp9pd3ra7o4f-xVlvsiNOzF7zrMHk124kuRtX_q5k3bMeO5t0LnG3LEEJuHLKZhKOYjQj7WB4dVnOtkTBG5cV4_9E4vv1KznH6Mt9SXAaTjbzJKrs.json?ccb=10-5&oh=00_AfDqP_wnEdETQz9n69Z9-dqV1xUzWqTpU_wxehG7JvKtMg&oe=658DDFC5&_nc_sid=a7aa5b\"\n",
        "images = \"https://scontent.fplu8-1.fna.fbcdn.net/m1/v/t6/An8hVtaVFSLA4yMZFPktRgsXzMN0lbpzHWAXmD3nHmtOt0pV9u5aUW2XbTTDB2w4MgEFSWAjPz34t0chIVdMaGXDIBZ2xPGqicVHKcd1wMqEy76lMac.zip?ccb=10-5&oh=00_AfBKkJzUTrbsjTddDHf4UzK2zrqtUukVNunWJdeEoNsGCw&oe=658DBFBE&_nc_sid=a7aa5b\"\n",
        "\n",
        "ego_objects_root = \"EgoObjects\"\n",
        "\n",
        "if not os.path.isfile(f\"${ego_objects_root}/data/EgoObjectsV1_unified_metadata.json\"):\n",
        "    wget.download(metadata, f\"${ego_objects_root}/data/EgoObjectsV1_unified_metadata.json\")\n",
        "\n",
        "if not os.path.isfile(f\"${ego_objects_root}/data/EgoObjectsV1_unified_train.json\"):\n",
        "    wget.download(train, f\"${ego_objects_root}/data/EgoObjectsV1_unified_train.json\")\n",
        "\n",
        "if not os.path.isfile(f\"${ego_objects_root}/data/EgoObjectsV1_unified_eval.json\"):\n",
        "    wget.download(eval, f\"${ego_objects_root}/data/EgoObjectsV1_unified_eval.json\")\n",
        "    \n",
        "if not os.path.isfile(f\"${ego_objects_root}/data/EgoObjectsV1_images.zip\"):\n",
        "    wget.download(images, f\"${ego_objects_root}/data/EgoObjectsV1_images.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "!git clone https://github.com/facebookresearch/EgoObjects.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(2, './EgoObjects/egoobjects_api')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import logging\n",
        "import unittest\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "from egoobjects import EgoObjects, FILTER_OPTS\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "gt_json_file = \"./EgoObjects/data/EgoObjectsV1_unified_train.json\"\n",
        "metadata_json_file = \"./EgoObjects/data/EgoObjectsV1_unified_metadata.json\"\n",
        "\n",
        "def get_egoobjects_meta(metadata_path: str):\n",
        "    \"\"\"\n",
        "    return metadata dictionary with 4 keys:\n",
        "        cat_det_cats\n",
        "        inst_det_cats\n",
        "        cat_det_cat_id_2_cont_id\n",
        "        cat_det_cat_names\n",
        "    \"\"\"\n",
        "    with open(metadata_path, \"r\") as fp:\n",
        "        metadata = json.load(fp)\n",
        "\n",
        "    cat_det_cat_id_2_name = {cat[\"id\"]: cat[\"name\"] for cat in metadata[\"cat_det_cats\"]}\n",
        "    cat_det_cat_ids = sorted([cat[\"id\"] for cat in metadata[\"cat_det_cats\"]])\n",
        "    cat_det_cat_id_2_cont_id = {cat_id: i for i, cat_id in enumerate(cat_det_cat_ids)}\n",
        "    cat_det_cat_names = [cat_det_cat_id_2_name[cat_id] for cat_id in cat_det_cat_ids]\n",
        "\n",
        "    metadata[\"cat_det_cat_id_2_cont_id\"] = cat_det_cat_id_2_cont_id\n",
        "    metadata[\"cat_det_cat_names\"] = cat_det_cat_names\n",
        "    return metadata\n",
        "\n",
        "dataset_name = \"EgoObjects\"\n",
        "metadata = get_egoobjects_meta(metadata_json_file)\n",
        "MetadataCatalog.get(dataset_name).set(**metadata)\n",
        "metadata = MetadataCatalog.get(dataset_name)\n",
        "\n",
        "split = \"egoobjects_unified_det_train\"\n",
        "gt = EgoObjects(gt_json_file, metadata, filter_opts=FILTER_OPTS[split])\n",
        "print(f\"img ids: ${gt.get_img_ids()}\")\n",
        "print(f\"class ids: ${gt.get_class_ids()}\")\n",
        "print(f\"annot ids: ${gt.get_ann_ids()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6_-eYrgIMWh"
      },
      "source": [
        "# Model\n",
        "### Our architecture definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJXY7cXEIMWh"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "def _make_divisible(v, divisor, min_value=None):\n",
        "    \"\"\"\n",
        "    This function is taken from the original tf repo.\n",
        "    It ensures that all layers have a channel number that is divisible by 8\n",
        "    It can be seen here:\n",
        "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "    :param v:\n",
        "    :param divisor:\n",
        "    :param min_value:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "#dw\n",
        "class DepthWiseConvolution(nn.Sequential):\n",
        "    def __init__(self, in_fts, stride = 1):\n",
        "        super(DepthWiseConvolution,self).__init__(\n",
        "            nn.Conv2d(in_fts,in_fts,kernel_size=(3,3),stride=stride,padding=(1,1), groups=in_fts, bias=False),\n",
        "            nn.BatchNorm2d(in_fts),\n",
        "            nn.ReLU6(inplace=True))\n",
        "\n",
        "\n",
        "#pw\n",
        "class PointWiseConvolution(nn.Sequential):\n",
        "    def __init__(self,in_fts,out_fts):\n",
        "        super(PointWiseConvolution,self).__init__(\n",
        "            nn.Conv2d(in_fts,out_fts,kernel_size=(1,1),bias=False),\n",
        "            nn.BatchNorm2d(out_fts),\n",
        "            nn.ReLU6(inplace=True))\n",
        "\n",
        "\n",
        "class ConvBNReLU(nn.Sequential):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, groups=1, norm_layer=None):\n",
        "        padding = (kernel_size - 1) // 2\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        super(ConvBNReLU, self).__init__(\n",
        "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, groups=groups, bias=False),\n",
        "            norm_layer(out_planes),\n",
        "            nn.ReLU6(inplace=True)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self,inp, oup, stride, expand_ratio, norm_layer=nn.BatchNorm2d):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.stride = stride\n",
        "\n",
        "        hidden_dim = int(round(inp*expand_ratio))\n",
        "        layers = []\n",
        "        self.use_res_connect = self.stride == 1 and inp == oup\n",
        "\n",
        "        #pw\n",
        "        if expand_ratio != 1:\n",
        "            layers.append(PointWiseConvolution(inp,hidden_dim))\n",
        "\n",
        "        #dw\n",
        "        layers.extend([\n",
        "            DepthWiseConvolution(hidden_dim,stride),\n",
        "            #pw-linear\n",
        "            nn.Conv2d(hidden_dim,oup,1,1,0,bias=False),\n",
        "            nn.BatchNorm2d(oup)])\n",
        "\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "class OurObjectDetectionNet(nn.Module):\n",
        "    def __init__(self,bottleneckLayerDetail,inp = 3,num_classes = 50,width_mult = 1.0,round_nearest=8):\n",
        "        super(OurObjectDetectionNet, self).__init__()\n",
        "\n",
        "        self.out = None\n",
        "\n",
        "        bloco = Bottleneck\n",
        "        inverted_residual_setting = bottleneckLayerDetail\n",
        "\n",
        "        input_channel = 32\n",
        "        last_channel = 1280\n",
        "\n",
        "        input_channel = _make_divisible(input_channel*width_mult,round_nearest)\n",
        "        self.last_channel = _make_divisible(last_channel*width_mult,round_nearest)\n",
        "\n",
        "        #first layer\n",
        "        features = [ConvBNReLU(inp, input_channel, stride=2)]\n",
        "\n",
        "        #build layers\n",
        "        for t, c, n, s in inverted_residual_setting:\n",
        "            output_channel = _make_divisible(c*width_mult,round_nearest)\n",
        "            for i in range(n):\n",
        "                stride = s if i == 0 else 1\n",
        "                features.append(bloco(input_channel,output_channel,stride = stride,expand_ratio=t))\n",
        "                input_channel = output_channel\n",
        "\n",
        "\n",
        "        #last layer\n",
        "        features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1))\n",
        "\n",
        "        #make sequential\n",
        "        self.features = nn.Sequential(*features)\n",
        "\n",
        "        #classificador\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(self.last_channel, num_classes))\n",
        "\n",
        "    def __forward_impl(self, x):\n",
        "        x = self.features(x)\n",
        "        x = nn.functional.adaptive_avg_pool2d(x,1).reshape(x.shape[0],-1)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.__forward_impl(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model declaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhSGOJF5IT-j"
      },
      "outputs": [],
      "source": [
        "bottleneckLayerDetail = [\n",
        "    # t, c, n, s\n",
        "    [1, 16, 1, 1],\n",
        "    [6, 24, 2, 2],\n",
        "    [6, 32, 3, 2],\n",
        "    [6, 64, 4, 2],\n",
        "    [6, 96, 3, 1],\n",
        "    [6, 160, 3, 2],\n",
        "    [6, 320, 1, 1],\n",
        "]\n",
        "\n",
        "our_model = OurObjectDetectionNet(bottleneckLayerDetail)\n",
        "summary(our_model, (1,3,224,224))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKkPP8ZMIMWi"
      },
      "source": [
        "### MobileNet V2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8_CdcdxIMWi"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
        "\n",
        "mobilenet_model = mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psncm1i2IMWi"
      },
      "source": [
        "### Convert model for mobile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lh4WLM6IMWj"
      },
      "outputs": [],
      "source": [
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBxTOOdcIMWj"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "import os.path\n",
        "\n",
        "if not os.path.isfile(\"convert.py\"):\n",
        "    wget.download(\n",
        "        \"https://raw.githubusercontent.com/johnpolsh/inf721-tpfinal/main/colab/convert.py\",\n",
        "        \"convert.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YFid7LRIMWj"
      },
      "outputs": [],
      "source": [
        "from convert import convert_for_mobile\n",
        "\n",
        "convert_for_mobile(mobilenet_model, \"object_detection\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
