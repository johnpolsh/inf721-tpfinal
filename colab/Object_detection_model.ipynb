{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78CEeCESIMWb"
      },
      "source": [
        "# Setup\n",
        "### Default imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfznvUtUlvVN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fouOM7wxIMWg"
      },
      "source": [
        "### Select back-end device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaxflJNFIMWg"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch.set_default_device(device)\n",
        "\n",
        "print(f\"Using {device} as default device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6_-eYrgIMWh"
      },
      "source": [
        "# Model\n",
        "### Our architecture definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJXY7cXEIMWh"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "def _make_divisible(v, divisor, min_value=None):\n",
        "    \"\"\"\n",
        "    This function is taken from the original tf repo.\n",
        "    It ensures that all layers have a channel number that is divisible by 8\n",
        "    It can be seen here:\n",
        "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "    :param v:\n",
        "    :param divisor:\n",
        "    :param min_value:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "#dw\n",
        "class DepthWiseConvolution(nn.Sequential):\n",
        "    def __init__(self, in_fts, stride = 1):\n",
        "        super(DepthWiseConvolution,self).__init__(\n",
        "            nn.Conv2d(in_fts,in_fts,kernel_size=(3,3),stride=stride,padding=(1,1), groups=in_fts, bias=False),\n",
        "            nn.BatchNorm2d(in_fts),\n",
        "            nn.ReLU6(inplace=True))\n",
        "\n",
        "\n",
        "#pw\n",
        "class PointWiseConvolution(nn.Sequential):\n",
        "    def __init__(self,in_fts,out_fts):\n",
        "        super(PointWiseConvolution,self).__init__(\n",
        "            nn.Conv2d(in_fts,out_fts,kernel_size=(1,1),bias=False),\n",
        "            nn.BatchNorm2d(out_fts),\n",
        "            nn.ReLU6(inplace=True))\n",
        "\n",
        "\n",
        "class ConvBNReLU(nn.Sequential):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, groups=1, norm_layer=None):\n",
        "        padding = (kernel_size - 1) // 2\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        super(ConvBNReLU, self).__init__(\n",
        "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, groups=groups, bias=False),\n",
        "            norm_layer(out_planes),\n",
        "            nn.ReLU6(inplace=True)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    def __init__(self,inp, oup, stride, expand_ratio, norm_layer=nn.BatchNorm2d):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.stride = stride\n",
        "\n",
        "        hidden_dim = int(round(inp*expand_ratio))\n",
        "        layers = []\n",
        "        self.use_res_connect = self.stride == 1 and inp == oup\n",
        "\n",
        "        #pw\n",
        "        if expand_ratio != 1:\n",
        "            layers.append(PointWiseConvolution(inp,hidden_dim))\n",
        "\n",
        "        #dw\n",
        "        layers.extend([\n",
        "            DepthWiseConvolution(hidden_dim,stride),\n",
        "            #pw-linear\n",
        "            nn.Conv2d(hidden_dim,oup,1,1,0,bias=False),\n",
        "            nn.BatchNorm2d(oup)])\n",
        "\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "class OurObjectDetectionNet(nn.Module):\n",
        "    def __init__(self,bottleneckLayerDetail,inp = 3,num_classes = 50,width_mult = 1.0,round_nearest=8):\n",
        "        super(OurObjectDetectionNet, self).__init__()\n",
        "\n",
        "        self.out = None\n",
        "\n",
        "        bloco = Bottleneck\n",
        "        inverted_residual_setting = bottleneckLayerDetail\n",
        "\n",
        "        input_channel = 32\n",
        "        last_channel = 1280\n",
        "\n",
        "        input_channel = _make_divisible(input_channel*width_mult,round_nearest)\n",
        "        self.last_channel = _make_divisible(last_channel*width_mult,round_nearest)\n",
        "\n",
        "        #first layer\n",
        "        features = [ConvBNReLU(inp, input_channel, stride=2)]\n",
        "\n",
        "        #build layers\n",
        "        for t, c, n, s in inverted_residual_setting:\n",
        "            output_channel = _make_divisible(c*width_mult,round_nearest)\n",
        "            for i in range(n):\n",
        "                stride = s if i == 0 else 1\n",
        "                features.append(bloco(input_channel,output_channel,stride = stride,expand_ratio=t))\n",
        "                input_channel = output_channel\n",
        "\n",
        "\n",
        "        #last layer\n",
        "        features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1))\n",
        "\n",
        "        #make sequential\n",
        "        self.features = nn.Sequential(*features)\n",
        "\n",
        "        #classificador\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(self.last_channel, num_classes))\n",
        "\n",
        "    def __forward_impl(self, x):\n",
        "        x = self.features(x)\n",
        "        x = nn.functional.adaptive_avg_pool2d(x,1).reshape(x.shape[0],-1)\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.__forward_impl(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model declaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhSGOJF5IT-j"
      },
      "outputs": [],
      "source": [
        "bottleneckLayerDetail = [\n",
        "    # t, c, n, s\n",
        "    [1, 16, 1, 1],\n",
        "    [6, 24, 2, 2],\n",
        "    [6, 32, 3, 2],\n",
        "    [6, 64, 4, 2],\n",
        "    [6, 96, 3, 1],\n",
        "    [6, 160, 3, 2],\n",
        "    [6, 320, 1, 1],\n",
        "]\n",
        "\n",
        "our_model = OurObjectDetectionNet(bottleneckLayerDetail)\n",
        "summary(our_model, (1,3,224,224))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKkPP8ZMIMWi"
      },
      "source": [
        "### MobileNet V2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8_CdcdxIMWi"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
        "\n",
        "mobilenet_model = mobilenet_v2(weights=MobileNet_V2_Weights.IMAGENET1K_V2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psncm1i2IMWi"
      },
      "source": [
        "### Convert model for mobile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lh4WLM6IMWj"
      },
      "outputs": [],
      "source": [
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBxTOOdcIMWj"
      },
      "outputs": [],
      "source": [
        "import wget\n",
        "import os.path\n",
        "\n",
        "if not os.path.isfile(\"convert.py\"):\n",
        "    wget.download(\n",
        "        \"https://raw.githubusercontent.com/johnpolsh/inf721-tpfinal/main/colab/convert.py\",\n",
        "        \"convert.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YFid7LRIMWj"
      },
      "outputs": [],
      "source": [
        "from convert import convert_for_mobile\n",
        "\n",
        "convert_for_mobile(mobilenet_model, \"object_detection\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
